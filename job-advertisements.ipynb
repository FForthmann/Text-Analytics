{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('de_core_news_sm')\r\n"
     ]
    }
   ],
   "source": [
    "# Downloading necessary dependencies\n",
    "! pip install spacy pandas openpyxl -q\n",
    "! python -m spacy download de_core_news_sm -q"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:55:42.143188Z",
     "start_time": "2023-09-18T12:55:34.198036Z"
    }
   },
   "id": "47d4ece9567fb303"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Excel-Datei lesen\n",
    "df = pd.read_excel(r'Stellenausschreibungen_2022_HES.xlsx')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T13:10:39.919372Z",
     "start_time": "2023-09-18T13:10:39.467160Z"
    }
   },
   "id": "9d2006fd45a191e0"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                           count unique  \\\nTitel                        626    563   \nUnternehmen                  626    503   \nText                         626    623   \nUnternehmen - 1. Buchstabe   626     30   \n6 Gruppen                      6      6   \n5 Gruppen                      4      4   \n\n                                                                          top  \\\nTitel                                                    Data Analyst (m/w/d)   \nUnternehmen                                                     Volkswagen AG   \nText                        Stellenbeschreibung\\nAnstellungsart\\nVollzeit\\...   \nUnternehmen - 1. Buchstabe                                                  A   \n6 Gruppen                                                         Ende Teil 1   \n5 Gruppen                                                         Ende Teil 1   \n\n                           freq  \nTitel                        18  \nUnternehmen                   5  \nText                          2  \nUnternehmen - 1. Buchstabe   73  \n6 Gruppen                     1  \n5 Gruppen                     1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Titel</th>\n      <td>626</td>\n      <td>563</td>\n      <td>Data Analyst (m/w/d)</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>Unternehmen</th>\n      <td>626</td>\n      <td>503</td>\n      <td>Volkswagen AG</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>Text</th>\n      <td>626</td>\n      <td>623</td>\n      <td>Stellenbeschreibung\\nAnstellungsart\\nVollzeit\\...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Unternehmen - 1. Buchstabe</th>\n      <td>626</td>\n      <td>30</td>\n      <td>A</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>6 Gruppen</th>\n      <td>6</td>\n      <td>6</td>\n      <td>Ende Teil 1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5 Gruppen</th>\n      <td>4</td>\n      <td>4</td>\n      <td>Ende Teil 1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:55:42.230120Z",
     "start_time": "2023-09-18T12:55:42.217874Z"
    }
   },
   "id": "e945161166880140"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method NDFrame.head of                                                  Titel  \\\n0    (Junior) Controller - Financial Planning & Ana...   \n1                           (Junior) Sales Ops Analyst   \n2                         Web Analytics Expert (m/w/d)   \n3              Data Analysis / Datenauswertung (m/w/d)   \n4         Lead Data Analyst/Consultant (m/w/d), Berlin   \n..                                                 ...   \n621  (Senior) Data Analyst / Data Manager (w/m/d) C...   \n622           Senior Consultant Data Analytics (m/w/d)   \n623     (Senior) Business Analyst (m/w/d) Credit Lines   \n624              Business Analyst (m/w/d) Credit Lines   \n625                   Service Business Analyst (m/w/d)   \n\n                   Unternehmen  \\\n0                         1NCE   \n1                         1NCE   \n2                  21TORR GmbH   \n3    3P Services GmbH & Co. KG   \n4     9 friendly white rabbits   \n..                         ...   \n621         ZEIT Verlagsgruppe   \n622                         ZF   \n623  Zurich Gruppe Deutschland   \n624           Zurich Insurance   \n625     Оконная Компания Олимп   \n\n                                                  Text  \\\n0    Stellenbeschreibung\\nAnstellungsart\\nVollzeit\\...   \n1    Stellenbeschreibung\\nAnstellungsart\\nVollzeit\\...   \n2    Stellenbeschreibung\\nAnstellungsart\\nVollzeit\\...   \n3    Stellenbeschreibung\\nAnstellungsart\\nVollzeit\\...   \n4    Stellenbeschreibung\\nAnstellungsart\\nVollzeit\\...   \n..                                                 ...   \n621  Stellenbeschreibung\\nAnstellungsart\\nFestanste...   \n622  What's Next? Join ZF!\\nZF ist ein weltweit agi...   \n623  Stellenbeschreibung\\nAnstellungsart\\nVollzeit\\...   \n624  Stellenbeschreibung\\nAnstellungsart\\nVollzeit\\...   \n625  Stellenbeschreibung\\nAnstellungsart\\nFestanste...   \n\n    Unternehmen - 1. Buchstabe    6 Gruppen 5 Gruppen  \n0                            1          NaN       NaN  \n1                            1          NaN       NaN  \n2                            2          NaN       NaN  \n3                            3          NaN       NaN  \n4                            9          NaN       NaN  \n..                         ...          ...       ...  \n621                          Z          NaN       NaN  \n622                          Z          NaN       NaN  \n623                          Z          NaN       NaN  \n624                          Z  Ende Teil 6       NaN  \n625                          О          NaN       NaN  \n\n[626 rows x 6 columns]>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:55:42.246182Z",
     "start_time": "2023-09-18T12:55:42.230033Z"
    }
   },
   "id": "9f5a9df141daea35"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Lade das deutsche Spacy-Modell und die Stopwörter-Liste\n",
    "nlp = spacy.load(\"de_core_news_sm\", disable=[\"tagger\", \"parser\", \"ner\"])\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "# Methoden zur Tokenisierung mit und ohne stopwords\n",
    "def tokenize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "def tokenize_without_stopwords(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc if not (token.is_stop or token.is_punct)]\n",
    "\n",
    "def tokenize_only_stopwords(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc if token.is_stop]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:55:42.770644Z",
     "start_time": "2023-09-18T12:55:42.236012Z"
    }
   },
   "id": "cc5dc46126ce9fd7"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die fünf am häufigsten verwendeten Wörter (ohne Stopwörter) sind:\n",
      "Data: 1084 mal\n",
      "Stellenbeschreibung: 925 mal\n",
      "Kunden: 800 mal\n",
      "Analytics: 785 mal\n",
      "Team: 709 mal\n",
      "Analyse und Tokenisierung abgeschlossen und Ergebnisse gespeichert.\n"
     ]
    }
   ],
   "source": [
    "# Analyse der Spalte \"Text\"\n",
    "df[\"tokens\"] = df[\"Text\"].apply(tokenize_text)\n",
    "df[\"tokens_without_stopwords\"] = df[\"Text\"].apply(tokenize_without_stopwords)\n",
    "df[\"tokens_stopwords_only\"] = df[\"Text\"].apply(tokenize_only_stopwords)\n",
    "\n",
    "df[\"without_stopwords\"] = df[\"tokens_without_stopwords\"].apply(lambda x: \" \".join(x))\n",
    "df[\"stopwords_only\"] = df[\"tokens_stopwords_only\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# Analyse: Hier die Anzahl der Wörter ohne Stoppwörter und nur mit Stoppwörtern\n",
    "df[\"count_without_stopwords\"] = df[\"tokens_without_stopwords\"].apply(len)\n",
    "df[\"count_stopwords\"] = df[\"tokens_stopwords_only\"].apply(len)\n",
    "\n",
    "# Ermittlung der fünf am häufigsten verwendeten Wörter ohne Stopwörter\n",
    "all_words_without_stopwords = [word for sublist in df[\"tokens_without_stopwords\"].tolist() for word in sublist if word.strip()]\n",
    "word_freq = Counter(all_words_without_stopwords)\n",
    "most_common_words = word_freq.most_common(7)  # Hole die 7 häufigsten, da wir möglicherweise 2 ignorieren müssen\n",
    "\n",
    "# Filtere die leeren Zeichenketten und Satzzeichen aus der meistverwendeten Liste heraus\n",
    "filtered_most_common_words = [item for item in most_common_words if item[0].strip() and not all(char in ':;,.-?!' for char in item[0])][:5]\n",
    "\n",
    "print(\"Die fünf am häufigsten verwendeten Wörter (ohne Stopwörter) sind:\")\n",
    "for word, freq in filtered_most_common_words:\n",
    "    print(f\"{word}: {freq} mal\")\n",
    "    \n",
    "# Speichern derErgebnisse in einer neuen Excel-Datei\n",
    "df.to_excel(\"Stellenausschreibungen_2022_HES-solutions.xlsx\", index=False)\n",
    "\n",
    "print(\"Analyse und Tokenisierung abgeschlossen und Ergebnisse gespeichert.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:56:48.977965Z",
     "start_time": "2023-09-18T12:55:42.781464Z"
    }
   },
   "id": "8aff3f645df9e8b6"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die fünf am häufigsten verwendeten Wörter (einschließlich Stopwörter) sind:\n",
      "und: 13794 mal\n",
      ",: 11843 mal\n",
      ".: 7036 mal\n",
      "der: 4449 mal\n",
      "in: 4223 mal\n"
     ]
    }
   ],
   "source": [
    "# Ausgabe inklusive Stopwörtern\n",
    "all_words_with_stopwords = [word for sublist in df[\"tokens\"].tolist() for word in sublist if word.strip()]\n",
    "word_freq_with_stopwords = Counter(all_words_with_stopwords)\n",
    "most_common_words_with_stopwords = word_freq_with_stopwords.most_common(7)\n",
    "\n",
    "# Filtere leere Zeichenketten aus der meistverwendeten Liste heraus\n",
    "filtered_most_common_words_with_stopwords = [item for item in most_common_words_with_stopwords if item[0].strip()][:5]\n",
    "\n",
    "print(\"Die fünf am häufigsten verwendeten Wörter (einschließlich Stopwörter) sind:\")\n",
    "for word, freq in filtered_most_common_words_with_stopwords:\n",
    "    print(f\"{word}: {freq} mal\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:56:49.042754Z",
     "start_time": "2023-09-18T12:56:49.016621Z"
    }
   },
   "id": "866a828f3bf5cbf9"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die fünf am häufigsten genannten Wörter (ohne Stopwörter) basierend auf der TF-IDF-Gewichtung sind:\n",
      "data: 25.069415346422648\n",
      "analytics: 20.72202087536447\n",
      "kunden: 18.14103031079909\n",
      "stellenbeschreibung: 17.12528376136759\n",
      "bi: 15.818371865945169\n"
     ]
    }
   ],
   "source": [
    "# Ausgabe mit Gewichtung zwischen einzelnen Stellenanzeigen \n",
    "\n",
    "# Verwende den TfidfVectorizer, um TF-IDF-Gewichtungen zu berechnen\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "\n",
    "# Vereinigen Sie alle tokenisierten Wörter ohne Stopwörter in einzelnen Textstrings\n",
    "texts_without_stopwords = df[\"tokens_without_stopwords\"].apply(lambda x: ' '.join(x)).tolist()\n",
    "\n",
    "# TF-IDF-Gewichtung berechnen\n",
    "tfidf_matrix = vectorizer.fit_transform(texts_without_stopwords)\n",
    "\n",
    "# Summieren Sie die TF-IDF-Werte für jedes Wort und ordnen Sie sie\n",
    "word2tfidf = dict(zip(vectorizer.get_feature_names_out(), tfidf_matrix.sum(axis=0).tolist()[0]))\n",
    "sorted_word2tfidf = sorted(word2tfidf.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "print(\"Die fünf am häufigsten genannten Wörter (ohne Stopwörter) basierend auf der TF-IDF-Gewichtung sind:\")\n",
    "for word, score in sorted_word2tfidf[:5]:\n",
    "    print(f\"{word}: {score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:57:24.294387Z",
     "start_time": "2023-09-18T12:57:24.148733Z"
    }
   },
   "id": "b4f604cdefb6acca"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5\n",
      "0  1.000000  0.512378  0.024502  0.050358  0.047722  0.042538\n",
      "1  0.512378  1.000000  0.025809  0.036963  0.060452  0.056364\n",
      "2  0.024502  0.025809  1.000000  0.041949  0.095298  0.048603\n",
      "3  0.050358  0.036963  0.041949  1.000000  0.053153  0.045593\n",
      "4  0.047722  0.060452  0.095298  0.053153  1.000000  0.095895\n",
      "5  0.042538  0.056364  0.048603  0.045593  0.095895  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Berechnung der Cosinus-Ähnlichkeit für die TF-IDF-Matrix\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# In einen Pandas DataFrame umwandeln für eine bessere Ansicht\n",
    "df_cosine_sim = pd.DataFrame(cosine_similarities)\n",
    "\n",
    "# Ausgabe der ersten 6 Zeilen und Spalten, um einen Überblick zu bekommen. Hier werden Ähnlichkeiten zwischen ganzen Beschreibungen gezeigt.\n",
    "print(df_cosine_sim.iloc[:6, :6])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T13:13:20.168889Z",
     "start_time": "2023-09-18T13:13:20.130256Z"
    }
   },
   "id": "d69df09b002a929f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
